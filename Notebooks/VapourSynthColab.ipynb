{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VapourSynthColab.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/AlphaAtlas/VapourSynthColab/blob/master/VapourSynthColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"-ybk7sETcjF8"},"source":["Welcome to VapourSynth in Colab!\n","\n","Basic usage instructions: run the setup script, and run all the tabs in the \"processing\" script for example output.\n","\n","For links to instructions, tutorials, and help, see https://github.com/AlphaAtlas/VapourSynthColab"]},{"cell_type":"markdown","metadata":{"id":"t5WlZQzIB4z2"},"source":["# Init\n"]},{"cell_type":"code","metadata":{"id":"yt0409nxWvV_","cellView":"form"},"source":["#@title Check GPU\n","#@markdown Run this to connect to a Colab Instance, and see what GPU Google gave you.\n","\n","gpu = !nvidia-smi --query-gpu=gpu_name --format=csv\n","print(gpu[1])\n","print(\"The Tesla T4 and P100 are fast and support hardware encoding. The K80 and P4 are slower.\")\n","print(\"Sometimes resetting the instance in the 'runtime' tab will give you a different GPU.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGwOv6tZ1NTg"},"source":["#@title Setup {display-mode: \"form\"}\n","#@markdown Run this to install VapourSynth, VapourSynth plugins and scripts, as well as some example upscaling models.\n","#NOTE: running this more than once may or may not work. \n","#The buggy console output is due to the threaded installing\n","#Currently TPU support is broken and incomplete, but it isn't particularly useful since it doesn't support opencl anyway \n","\n","#Init\n","import os, sys, shutil, tempfile\n","import collections\n","from datetime import datetime, timedelta\n","import requests\n","import threading\n","import ipywidgets as widgets\n","from IPython import display\n","import PIL\n","from google.colab import files\n","import time\n","%cd /\n","\n","\n","#Function defs\n","#---------------------------------------------------------\n","\n","#Like shutil.copytree(), but doesn't complain about existing directories\n","#Note this is fixed in newer version of Python 3\n","def copytree(src, dst, symlinks=False, ignore=None):\n","  for item in os.listdir(src):\n","    s = os.path.join(src, item)\n","    d = os.path.join(dst, item)\n","    if os.path.isdir(s):\n","      shutil.copytree(s, d, symlinks, ignore)\n","    else:\n","      shutil.copy2(s, d)\n","\n","#Download and extract the .py scripts from the VapourSynth fatpack\n","def download_fatpack_scripts():\n","  %cd /\n","  print(\"Downloading VS FatPack Scripts...\")\n","  dlurl = r\"https://github.com/theChaosCoder/vapoursynth-portable-FATPACK/releases/download/r3/VapourSynth64Portable_2019_11_02.7z\"\n","  with tempfile.TemporaryDirectory() as t:\n","    dpath = os.path.join(t, \"VapourSynth64Portable_2019_11_02.7z\")\n","    os.chdir(t)\n","    !wget {dlurl}\n","    %cd /\n","    !7z x -o{t} {dpath}\n","    scriptsd = os.path.abspath(os.path.join(t, \"VapourSynth64Portable\", \"Scripts\"))\n","    s = os.path.normpath(\"VapourSynthImports\")\n","    os.makedirs(s, exist_ok = True)\n","    copytree(scriptsd, s)\n","    sys.path.append(s)\n","  \n","  #Get some additional scripts.\n","  !wget -O /VapourSynthImports/muvsfunc_numpy.py https://raw.githubusercontent.com/WolframRhodium/muvsfunc/master/Collections/muvsfunc_numpy.py\n","  !wget -O /VapourSynthImports/edi_rpow2.py https://gist.githubusercontent.com/YamashitaRen/020c497524e794779d9c/raw/2a20385e50804f8b24f2a2479e2c0f3c335d4853/edi_rpow2.py\n","  !wget -O /VapourSynthImports/BMToolkit.py https://raw.githubusercontent.com/IFeelBloated/BlockMatchingToolkit/master/BMToolkit.py\n","  if accelerator == \"CUDA\":\n","    !wget -O /VapourSynthImports/Alpha_CuPy.py https://raw.githubusercontent.com/AlphaAtlas/VapourSynth-Super-Resolution-Helper/master/Scripts/Alpha_CuPy.py\n","    !wget -O /VapourSynthImports/dpid.cu https://raw.githubusercontent.com/WolframRhodium/muvsfunc/master/Collections/examples/Dpid_cupy/dpid.cu\n","    !wget -O /VapourSynthImports/bilateral.cu https://raw.githubusercontent.com/WolframRhodium/muvsfunc/master/Collections/examples/BilateralGPU_cupy/bilateral.cu\n","\n","  #Get an example model:\n","  import gdown\n","  gdown.download(r\"https://drive.google.com/uc?id=1KToK9mOz05wgxeMaWj9XFLOE4cnvo40D\", \"/content/4X_Box.pth\", quiet=False)\n","\n","def getdep1():\n","  %cd /\n","  #Install apt-fast, for faster installing\n","  !/bin/bash -c \"$(curl -sL https://git.io/vokNn)\"\n","  #Get some basic dependancies\n","  !apt-fast install -y -q -q subversion davfs2 p7zip-full p7zip-rar ninja-build \n","\n","#Get VapourSynth and ImageMagick built just for a colab environment\n","def getvs():\n","  %cd /\n","  #%cd var/cache/apt/archives\n","  #Artifacts hosted on bintray. If they fail to install, they can be built from source. \n","  !curl -L \"https://dl.bintray.com/alphaatlas100/vapoursynth-colab/imagemagick_7.0.9-8-1_amd64.deb\" -o /var/cache/apt/archives/imagemagick.deb\n","  !dpkg -i /var/cache/apt/archives/imagemagick.deb\n","  !ldconfig /usr/local/lib\n","  !curl -L \"https://dl.bintray.com/alphaatlas100/vapoursynth-colab/vapoursynth_48-1_amd64.deb\" -o /var/cache/apt/archives/vapoursynth.deb\n","  !dpkg -i /var/cache/apt/archives/vapoursynth.deb\n","  !ldconfig /usr/local/lib\n","  #%cd /\n","\n","def getvsplugins():\n","  %cd /\n","  #Allow unauthenticated sources\n","  if not os.path.isfile(\"/etc/apt/apt.conf.d/99myown\"):\n","    with open(\"/etc/apt/apt.conf.d/99myown\", \"w+\") as f:\n","      f.write(r'APT::Get::AllowUnauthenticated \"true\";')\n","  sources = \"/etc/apt/sources.list\"\n","  #Backup original apt sources file, just in case\n","  with tempfile.TemporaryDirectory() as t:\n","    tsources = os.path.join(t, os.path.basename(sources))\n","    shutil.copy(sources, tsources)\n","    #Add deb-multimedia repo\n","    #Because building dozens of VS plugins is not fun, and takes forever\n","    with open(sources, \"a+\") as f:\n","      deb = \"deb https://www.deb-multimedia.org sid main non-free\\n\"\n","      if not \"deb-multimedia\" in f.read():\n","        f.write(deb)\n","\n","    with open(sources, \"a+\") as f:\n","      #Temporarily use Debian unstable for some required dependencies \n","      if not \"ftp.us.debian.org\" in f.read():\n","        f.write(\"deb http://ftp.us.debian.org/debian/ sid main\\n\")\n","    !add-apt-repository -y ppa:deadsnakes/ppa\n","    !apt-fast update -oAcquire::AllowInsecureRepositories=true\n","    !apt-fast install -y --allow-unauthenticated deb-multimedia-keyring\n","    !apt-fast update  \n","\n","    #Parse plugins to install\n","    out = !apt-cache search vapoursynth\n","    vspackages = \"\"\n","    #exclude packages with these strings in the name\n","    exclude = [\"waifu\", \"wobbly\", \"editor\", \"dctfilter\", \"vapoursynth-dev\", \"vapoursynth-doc\"]\n","    for line in out:\n","      p =  line.split(\" - \")[0].strip()\n","      if not any(x in p for x in exclude) and \"vapoursynth\" in p and p != \"vapoursynth\":\n","        vspackages = vspackages + p + \" \"\n","    print(vspackages)\n","    #Install VS plugins and a newer ffmpeg build\n","    !apt-fast install -y --allow-unauthenticated --no-install-recommends ffmpeg youtube-dl libzimg-dev {vspackages} libfftw3-3 libfftw3-double3 libfftw3-dev libfftw3-bin libfftw3-double3 libfftw3-single3 checkinstall\n","    #Get a tiny example video\n","    !youtube-dl -o /content/enhance.webm -f 278 https://www.youtube.com/watch?v=I_8ZH1Ggjk0\n","    #Restore original sources\n","    os.remove(sources)\n","    shutil.copy(tsources, sources)\n","  #Congrats! Apt may or may not be borked.\n","  copytree(\"/usr/lib/x86_64-linux-gnu/vapoursynth\", \"/usr/local/lib/vapoursynth\")\n","  !ldconfig /usr/local/lib/vapoursynth\n","\n","#Install vapoursynth python modules\n","def getpythonstuff():\n","  %cd /\n","  !python3.6 -m pip install vapoursynth meson opencv-python\n","\n","def cudastuff():\n","    %cd /\n","    out = !nvcc --version\n","    cudaver = (str(out).split(\"Cuda compilation tools, release \")[1].split(\", \")[0].replace(\".\", \"\"))\n","    #Note this download sometimes times out\n","    !python3.6 -m pip install mxnet-cu{cudaver} #cupy-cuda{cudaver}\n","    !pip install git+https://github.com/AlphaAtlas/VSGAN.git\n","\n","    #Mxnet stuff\n","    \n","    modelurl = \"https://github.com/WolframRhodium/Super-Resolution-Zoo/trunk\"\n","    if os.path.isdir(\"/NeuralNetworks\"):\n","      !svn update --set-depth immediates /NeuralNetworks\n","      !svn update --set-depth infinity /NeuralNetworks/ARAN\n","    else:\n","      !svn checkout --depth immediates {modelurl} /NeuralNetworks\n","\n","def makesrcd(name):\n","  %cd /\n","  srpath = os.path.abspath(os.path.join(\"/src\", name))\n","  os.makedirs(srpath, exist_ok = False)\n","  %cd {srpath}\n","\n","def mesongit(giturl):\n","  p = os.path.basename(giturl)[:-4]\n","  makesrcd(p)\n","  !git clone {giturl}\n","  %cd {p}\n","  !meson build\n","  !ninja -C build\n","  !ninja -C build install\n","\n","#Taken from https://stackoverflow.com/a/31614591\n","#Allows exceptions to be caught from threads\n","from threading import Thread\n","\n","class PropagatingThread(Thread):\n","    def run(self):\n","        self.exc = None\n","        try:\n","            if hasattr(self, '_Thread__target'):\n","                # Thread uses name mangling prior to Python 3.\n","                self.ret = self._Thread__target(*self._Thread__args, **self._Thread__kwargs)\n","            else:\n","                self.ret = self._target(*self._args, **self._kwargs)\n","        except BaseException as e:\n","            self.exc = e\n","\n","    def join(self):\n","        super(PropagatingThread, self).join()\n","        if self.exc:\n","            raise self.exc\n","        return self.ret\n","\n","\n","#Interpolation experiment\n","#%cd /\n","#os.makedirs(\"/videotools\")\n","#%cd /videotools\n","#!git clone https://github.com/sniklaus/pytorch-sepconv.git\n","#%cd /\n","\n","#Function for testing vapoursynth scripts\n","#Takes the path of the script, and a boolean for generating a test frame.\n","\n","#-----------------------------------------------------------\n","\n","#Init functions are threaded for speed\n","#\"PropagatingThread\" class is used to return exceptions from threads, otherwise they fail silently\n","\n","t1 = PropagatingThread(target = getdep1)\n","t1.start()\n","print(\"apt init thread started\")\n","\n","t2 = PropagatingThread(target = download_fatpack_scripts)\n","t2.start()\n","print(\"VS script downloader thread started.\")\n","\n","#Get rid of memory usage log spam from MXnet\n","os.environ[\"TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD\"] = \"107374182400\"\n","\n","#Check for an accelerator\n","accelerator = None\n","gpu = None\n","if 'COLAB_TPU_ADDR' in os.environ:\n","  #WIP\n","  raise Exception(\"TPUs are (currently) not supported! Please use a GPU or CPU instance.\")\n","else:\n","  #Check for Nvidia GPU, and identify it \n","  out = !command -v nvidia-smi\n","  if out != []:\n","    out = !nvidia-smi\n","    for l in out:\n","      if \"Driver Version\" in l:\n","        accelerator = \"CUDA\"\n","        print(\"Nvidia GPU detected:\")\n","        gpu = !nvidia-smi --query-gpu=gpu_name --format=csv\n","        gpu = gpu[1]\n","        #print(\"Tesla K80 < Tesla T4 < Tesla P100\")\n","        break\n","if accelerator == None:\n","  print(\"Warning: No Accelerator Detected!\")\n","\n","t1.join()\n","print(\"Apt init thread done.\")\n","\n","t1 = PropagatingThread(target = getvs)\n","t1.start()\n","print(\"Vapoursynth/Imagemagick downloader thread started.\")\n","t1.join()\n","print(\"Vapoursynth/Imagemagick installed\")\n","\n","t3 = PropagatingThread(target = getpythonstuff)\n","t3.start()\n","print(\"Pip thread started\")\n","\n","t1 = PropagatingThread(target = getvsplugins)\n","t1.start()\n","print(\"VS plugin downloader thread started.\")\n","\n","t3.join()\n","print(\"pip thread done\")\n","\n","if accelerator == \"TPU\":\n","  #WIP!\n","  pass\n","\n","elif accelerator == \"CUDA\":\n","  t3 = PropagatingThread(target = cudastuff)\n","  t3.start()\n","  print(\"CUDA pip thread started.\")\n","else:\n","  pass\n","\n","t2.join()\n","print(\"VS script downloader thread done.\")\n","\n","t3.join()\n","print(\"CUDA pip thread done.\")\n","\n","t1.join()\n","print(\"VS plugin thread done.\")\n","\n","\n","\n","#Build some more plugins(s)\n","#TODO: Build without changing working directory, or try the multiprocessing module, so building can run asynchronously \n","print(\"Building additional plugins\")\n","mesongit(r\"https://github.com/HomeOfVapourSynthEvolution/VapourSynth-DCTFilter.git\")\n","mesongit(r\"https://github.com/HomeOfVapourSynthEvolution/VapourSynth-TTempSmooth.git\")\n","\n","googpath = None\n","%cd /\n","\n","Clear_Console_Output_When_Done = True #@param {type:\"boolean\"}\n","if Clear_Console_Output_When_Done:\n","  display.clear_output()\n","#if gpu is not None:\n","#  print(gpu[1])\n","#  print(\"A Tesla T4 or P100 is significantly faster than a K80\")\n","#  print(\"And the K80 doesn't support hardware encoding.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bl2luwktJur6"},"source":["#@title Mount Google Drive\n","#@markdown Highly recommended!\n","\n","import os\n","%cd /\n","\n","#Check if Google Drive is mounted, and mount if its not.\n","googpath = os.path.abspath(os.path.join(\"gdrive\", \"My Drive\"))\n","if not os.path.isdir(googpath):\n","  from google.colab import drive\n","  drive.mount('/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ7jll23J73k"},"source":["#@title Mount a Nextcloud Drive\n","\n","import os\n","nextcloud = \"/nextcloud\"\n","os.makedirs(nextcloud, exist_ok=True)\n","Nextcloud_URL = \"https://us.hostiso.cloud/remote.php/webdav/\" #@param {type:\"string\"}\n","\n","%cd /\n","if os.path.isfile(\"/etc/fstab\"):\n","  os.remove(\"/etc/fstab\")\n","with open(\"/etc/fstab\" , \"a\") as f:\n","  f.write(Nextcloud_URL + \" \" + nextcloud + \" davfs user,rw,auto 0 0\")\n","!mount {nextcloud}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZRtpK-cvCONa"},"source":["# Processing"]},{"cell_type":"markdown","metadata":{"id":"9uSOzH9jcbTt"},"source":[""]},{"cell_type":"code","metadata":{"id":"kF_1IcgVOWg2"},"source":["%%writefile /content/autogenerated.vpy\n","\n","#This is the Vapoursynth Script!\n","#Running this cell will write the code in this cell to disk, for VSPipe to read.\n","#Later cells will check to see if it executes.\n","#Edit it just like a regular python VS script.\n","#Search for functions and function reference in http://vsdb.top/, or browse the \"VapourSynthImports\" folder. \n","\n","#Import functions\n","import sys, os, cv2\n","sys.path.append('/VapourSynthImports')\n","import vapoursynth as vs\n","import vsgan as VSGAN\n","import mvsfunc as mvf\n","#import muvsfunc as muf\n","#import fvsfunc as fvf\n","import havsfunc as haf\n","import Alpha_CuPy as ape\n","import muvsfunc_numpy as mufnp\n","#import BMToolkit as bm\n","import G41Fun as G41\n","#import vsutil as util\n","#import edi_rpow2 as edi\n","#import kagefunc as kage\n","#import lostfunc as lost\n","#import vsTAAmbk as taa\n","#import xvs as xvs\n","from vapoursynth import core\n","\n","#Set RAM cache size, in MB\n","core.max_cache_size = 10500\n","\n","#Get Video(s) or Image(s). ffms2 (ffmpeg) or imwri (imagemagick) will read just about anything.\n","#Lsmash sometimes works if ffms2 failes, d2v reads mpeg2 files\n","clip = core.ffms2.Source(r\"/content/enhance.webm\")\n","#clip = core.lsmas.LWLibavSource(\"/tmp/%d.png\")\n","#clip = core.imwri.Read(\"testimage.tiff\")\n","\n","#Store source for previewing\n","src = clip\n","\n","#Convert to 16 bit YUV for preprocessing\n","#clip = core.resize.Spline36(clip, format = vs.YUV444P16)\n","\n","#Deinterlace\n","#clip = G41.QTGMC(clip, Preset='Medium')\n","\n","#Mild deblocking\n","#clip = fvf.AutoDeblock(clip)\n","\n","#Convert to floating point RGB\n","clip = mvf.ToRGB(clip, depth = 32)\n","\n","#Spatio-temportal GPU denoiser. https://github.com/Khanattila/KNLMeansCL/wiki/Filter-description\n","clip = core.knlm.KNLMeansCL(clip, a = 8, d = 4, h = 1.4)\n","\n","\n","preupscale = clip\n","#Run ESRGAN model. See https://upscale.wiki/wiki/Model_Database\n","vsgan_device = VSGAN.VSGAN()\n","vsgan_device.load_model(model=r\"/content/4X_Box.pth\", scale=4)\n","clip = vsgan_device.run(clip=clip, chunk = False,  pad = 16)\n","\n","clip = core.knlm.KNLMeansCL(clip, a = 7, d = 3, h = 1.4)\n","\n","\n","\n","#Run MXNet model. See the \"MXNet\" cell.\n","#Tensorflow models are also supported!\n","#sr_args = dict(model_filename=r'/NeuralNetworks/ARAN/aran_c0_s1_x4', up_scale=4, device_id=0, block_w=256, block_h=128, is_rgb_model=True, pad=None, crop=None, pre_upscale=False)\n","#clip = mufnp.super_resolution(clip, **sr_args)\n","\n","#HQ downscale on the GPU with dpid\n","#clip = ape.GPU_Downscale(clip, width = 3840, height = 2160)\n","\n","#Convert back to YUV 444 format/Rec 709 colorspace\n","clip = core.resize.Spline36(clip, format = vs.YUV444P16, matrix_s = \"709\")\n","\n","#Strong temporal denoiser and stabilizer with the LR as a motion reference clip, for stabilizing.\n","prefilter = core.resize.Spline36(preupscale, format = clip.format, width = clip.width, height = clip.height, matrix_s = \"709\")\n","clip = G41.SMDegrain(clip, tr=3, RefineMotion=True, pel = 1, prefilter = prefilter)\n","\n","#Another CPU denoiser/stabilizer. \"very high\" is very slow.\n","#clip = haf.MCTemporalDenoise(clip, settings = \"very high\", useTTmpSm = True, maxr=4, stabilize = True)\n","\n","#Stabilized Anti Aliasing, with some GPU acceleration\n","#clip = taa.TAAmbk(clip, opencl=True, stabilize = 3)\n","\n","#Example sharpeners that work well on high-res images\n","#Masks or mvf.limitfilter are good ways to keep artifacts in check\n","#clip = core.warp.AWarpSharp2(clip)\n","#clip = G41.NonlinUSM(clip, z=3, sstr=0.28, rad=9, power=1)\n","\n","#High quality, strong debanding\n","#clip = fvf.GradFun3(clip, smode = 2)\n","\n","#Convert back to 8 bit YUV420 for output. \n","clip = core.resize.Spline36(clip, format = vs.YUV420P8, matrix_s = \"709\", dither_type = \"error_diffusion\")\n","\n","#Interpolate to double the source framerate\n","#super = core.mv.Super(inter)\n","#backward_vectors = core.mv.Analyse(super, isb = True,  overlap=4, search = 3)\n","#forward_vectors = core.mv.Analyse(super, isb = False, overlap=4, search = 3)\n","#inter = core.mv.FlowFPS(inter, super, backward_vectors, forward_vectors, num=0, den=0)\n","\n","#Stack the source on top of the processed clip for comparison\n","src = core.resize.Point(src, width = clip.width, height = clip.height, format = clip.format)\n","#clip = core.std.StackVertical([clip, src])\n","#Alternatively, interleave the source and slow down the framerate for easy comparison.\n","clip = core.std.Interleave([clip, src])\n","clip = core.std.AssumeFPS(clip, fpsnum = 2)\n","\n","#clip = core.std.SelectEvery(clip=clip, cycle=48, offsets=[0,1])\n","\n","clip.set_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCutJf-PID0N","cellView":"form"},"source":["#@title Preview Options\n","#@markdown Run this cell to check the .vpy script, and set preview options. \n","#@markdown * Software encoding is relatively slow on colab's single CPU core, but returns a smaller video.\n","#@markdown * Hardware encoding doesn't work on older GPUs or a TPU, but can be faster.\n","#@markdown * Sometimes video previews don't work. Chrome seems more reliable than Firefox, but its video player doesn't support scrubbing. Alternatively, you can download the preview in the \"/content\" folder with the Colab UI.\n","#@markdown * HEVC support in browsers is iffy.\n","#@markdown * PNG previews are more reliable, but less optimal.  \n","#@markdown * In video previews, you can interleave the source and processed clips and change the framerate for easy comparisons. \n","#@markdown ***\n","\n","#TODO: Make vpy file path editable\n","vpyscript = \"/content/autogenerated.vpy\"\n","#@markdown Use hardware encoding.\n","Hardware_Encoding = True #@param {type:\"boolean\"}\n","#@markdown Encode preview as lossless or high quality lossy video\n","Lossless = False #@param {type:\"boolean\"}\n","#@markdown Use HEVC instead of AVC for preview. Experimental.\n","HEVC = False #@param {type:\"boolean\"}\n","#@markdown Generate a single PNG instead of a video.\n","Write_PNG = False #@param {type:\"boolean\"}\n","#@markdown Don't display any video preview, just write it to /content\n","Display_Video = False #@param {type:\"boolean\"}\n","#@markdown Number of preview frames to generate\n","preview_frames =  120 #@param {type:\"integer\"}\n","#Check script with test frame (for debugging)\n","Test_Frame = False \n","\n","from IPython.display import clear_output\n","import ipywidgets as widgets\n","from pprint import pprint\n","\n","\n","\n","def checkscript(vpyfile, checkoutput):\n","  \n","  #Clear the preview cache folder, as the script could have changed\n","  \n","  quotepath = r'\"' + vpyfile + r'\"'\n","  print(\"Testing script...\")\n","  if checkoutput:\n","  #See if the script will really output a frame\n","    test = !vspipe -y -s 0 -e 0 {quotepath} .\n","  #Parse the script, and return information about it. \n","  rawinfo = !vspipe -i {quotepath} -\n","  #Store clip properties as a dict\n","  #I really need to learn regex...\n","  clipinfo = eval(r\"{\" + str(rawinfo)[1:].replace(r\"\\n\", r\"','\").replace(r\": \", r\"': '\")[:-1] + r\"}\")\n","  !clear\n","  if not isinstance(clipinfo, dict):\n","    print(rawinfo)\n","    raise Exception(\"Error parsing VapourSynth script!\")\n","  #print(\"Script output properties: \")\n","  #!echo {clipinfo}\n","  return clipinfo, rawinfo, quotepath\n","\n","#Make a preview button, and a frame slider\n","#Note that the slider won't appear with single frame scripts\n","%cd /\n","#display.clear_output()\n","!clear\n","clipinfo, rawinfo, quotepath = checkscript(vpyscript, Test_Frame)\n","frameslider = None\n","drawslider = int(clipinfo[\"Frames\"]) > 1\n","if drawslider:\n","  frameslider = widgets.IntSlider(value=0, max=(int(clipinfo[\"Frames\"]) - 1), layout=widgets.Layout(width='100%', height='150%'))\n","else:\n","  preview_frames = 1\n","fv = None\n","\n","\n","if not(preview_frames > 0 and preview_frames <= int(clipinfo[\"Frames\"])):\n","  raise Exception(\"preview_frames must be a valid integer\")\n","if drawslider:\n","  fv = int(frameslider.value)\n","else:\n","  fv = 0\n","\n","encstr = \"\"\n","previewfile = r\"/usr/local/share/jupyter/nbextensions/preview.mp4\"\n","if os.path.isfile(previewfile):\n","  os.remove(previewfile)\n","ev = min((int(fv + preview_frames - 1), int(clipinfo[\"Frames\"])- 1))\n","enctup = (Hardware_Encoding, HEVC, Lossless) \n","if enctup == (True, True, True):\n","  encstr = r\"-c:v hevc_nvenc -profile main10 -preset lossless -spatial_aq:v 1 -aq-strength 15 \"\n","elif enctup == (True, True, False):\n","  encstr = r\"-c:v hevc_nvenc -pix_fmt yuv420p10le -preset:v medium -profile:v main10 -spatial_aq:v 1 -aq-strength 15 -rc:v constqp -qp:v 9\"\n","elif enctup == (True, False, True):\n","  encstr = r\"-c:v h264_nvenc -preset lossless -profile high444p -spatial-aq 1 -aq-strength 15\"\n","elif enctup == (False, True, True):\n","  encstr = r\"-c:v libx265 -pix_fmt yuv420p10le -preset slow -x265-params lossless=1\"\n","elif enctup == (True, False, False):\n","  encstr = r\"-c:v h264_nvenc -pix_fmt yuv420p -preset:v medium -rc:v constqp -qp:v 10 -spatial-aq 1 -aq-strength 15\"\n","elif enctup == (False, False, True):\n","  encstr = r\"-c:v libx264 -preset veryslow -crf 0\"\n","elif enctup == (False, True, False):\n","  encstr = r\"-c:v libx265 -pix_fmt yuv420p10le -preset slow -crf 9\"\n","elif enctup == (False, False, False):\n","  encstr = r\"-c:v libx264 -pix_fmt yuv420p -preset veryslow -crf 9\"\n","else:\n","  raise Exception(\"Invalid parameters!\")\n","clear_output()\n","print(*rawinfo, sep = ' ')\n","print(\"Select the frame(s) you want to preview with the slider and 'preview frames', then run the next cell.\")\n","display.display(frameslider)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yp9D0XWAJF4t","cellView":"form"},"source":["#@title Generate Preview\n","\n","import os, time\n","\n","\n","previewdisplay = r\"\"\"\n","<video controls autoplay>\n","  <source src=\"/nbextensions/preview.mp4\" type='video/mp4;\"'>\n","  Your browser does not support the video tag.\n","</video>\n","\"\"\"\n","previewpng = \"/content/preview\" + str(frameslider.value) + \".png\"\n","if os.path.isfile(previewfile):\n","  os.remove(previewfile)\n","if os.path.isfile(previewpng):\n","  os.remove(previewpng)\n","frames = str(clipinfo[\"Frames\"])\n","end = min(frameslider.value + preview_frames - 1, int(clipinfo[\"Frames\"]) - 1)\n","if Write_PNG:\n","  !vspipe -y -s {frameslider.value} -e {frameslider.value} /content/autogenerated.vpy - | ffmpeg-y -hide_banner -loglevel warning -i pipe: {previewpng} \n","  if os.path.isfile(previewpng):\n","    import PIL\n","    display.display(PIL.Image.open(previewpng, mode='r'))\n","  else:\n","    raise Exception(\"Error generating preview!\")\n","else:\n","  out = !vspipe --progress -y -s {frameslider.value} -e {end} /content/autogenerated.vpy - | ffmpeg -y -hide_banner -progress pipe:1 -loglevel warning -i pipe: {encstr} {previewfile} | grep \"fps\"\n","  if os.path.isfile(previewfile):\n","    if os.path.isfile(\"/content/preview.mp4\"):\n","      os.remove(\"/content/preview.mp4\")\n","    !ln {previewfile} \"/content/preview.mp4\"\n","    clear_output()\n","    for temp in out:\n","      if \"Output\" in temp:\n","        print(temp)\n","    if Display_Video:\n","      display.display(display.HTML(previewdisplay))\n","  else:\n","    raise Exception(\"Error generating preview!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GBLpYMn_o-RN"},"source":["# Scratch Space\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"XfesPGOhaRh_"},"source":["#Do stuff here\n","\n","#Example ffmpeg script:\n","\n","!vspipe -y /content/autogenerated.vpy - | ffmpeg -i pipe: -c:v hevc_nvenc -profile:v main10 -preset lossless -spatial_aq:v 1 -aq-strength 15 \"/gdrive/My Drive/upscale.mkv\"\n","\n","#TODO: Figure out why vspipe's progress isn't showing up in colab."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XcXnvXYB2pq_"},"source":["# Extra Functions\n"]},{"cell_type":"code","metadata":{"id":"Qcnwt2Tgt_f_","cellView":"form"},"source":["#@title Build ImageMagick and VapourSynth for Colab\n","#@markdown VapourSynth needs to be built for Python 3.6, and Imagemagick needs to be built for the VapourSynth imwri plugin. The setup script pulls from bintray, but this cell will rebuild and reinstall them if those debs dont work. \n","#@markdown The built debs can be found in the \"src\" folder.\n","\n","#Get some requirements for building\n","def getbuildstuff():\n","  !apt-fast install software-properties-common autoconf automake libtool build-essential cython3 coreutils pkg-config\n","  !python3.6 -m pip install tesseract cython\n","\n","#Build imagemagick, for imwri and local image manipulation, and create a deb\n","def buildmagick():\n","  makesrcd(\"imagemagick\")\n","  !wget https://imagemagick.org/download/ImageMagick-7.0.9-8.tar.gz\n","  !tar xvzf ImageMagick-7.0.9-8.tar.gz\n","  %cd ImageMagick-7.0.9-8\n","  !./configure --enable-hdri=yes --with-quantum-depth=32\n","  !make -j 4 --quiet\n","  !sudo checkinstall -D --fstrans=no --install=yes --default --pakdir=/src --pkgname=imagemagick --pkgversion=\"8:7.0.9-8\"\n","  !ldconfig /usr/local/lib\n","\n","#Build vapoursynth for colab (python 3.6, Broadwell SIMD, etc.), and create a deb\n","def buildvs():\n","  makesrcd(\"vapoursynth\")\n","  !wget https://github.com/vapoursynth/vapoursynth/archive/R48.tar.gz\n","  !tar -xf R48.tar.gz\n","  %cd vapoursynth-R48\n","  !./autogen.sh\n","  !./configure --enable-imwri\n","  !make -j 4 --quiet\n","  !sudo checkinstall -D --fstrans=no --install=yes --default --pakdir=/src --pkgname=vapoursynth --pkgversion=48\n","  !ldconfig /usr/local/lib\n","  \n","getbuildstuff()\n","buildmagick()\n","buildvs()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5KWyJFEzW7H"},"source":["#@title MXnet\n","#@markdown This cell will pull pretrained models from https://github.com/WolframRhodium/Super-Resolution-Zoo\n","#@markdown For usage examples, see [this](https://github.com/WolframRhodium/muvsfunc/blob/master/Collections/examples/super_resolution_mxnet.vpy)\n","#@markdown and [this](https://github.com/WolframRhodium/Super-Resolution-Zoo/wiki/Explanation-of-configurations-in-info.md)\n","#Note that there's no release for the mxnet C++ plugin, and I can't get it to build in colab, but the header pulls and installs mxnet and the numpy super resolution function\n","n = \"ESRGAN\" #@param {type:\"string\"}\n","!svn update --set-depth infinity  NeuralNetworks/{n}"],"execution_count":null,"outputs":[]}]}