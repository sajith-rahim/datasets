{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"W2V_SpellChecker.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOIv6cUjzSrRWcrrwPUBh9x"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EKCE1c7E-NhA","executionInfo":{"status":"ok","timestamp":1614118808284,"user_tz":-330,"elapsed":880,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["import re\r\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BGbZU9K-m4A","executionInfo":{"status":"ok","timestamp":1614119726437,"user_tz":-330,"elapsed":398637,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}},"outputId":"6ef3bef9-dedc-4b19-887f-7dd6fbba6382"},"source":["# Download for here : https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\r\n","\r\n","import gensim.downloader as api\r\n","\r\n","model = api.load(\"word2vec-google-news-300\")\r\n","word_vectors = model.wv "],"execution_count":4,"outputs":[{"output_type":"stream","text":["[=================================================-] 99.9% 1661.5/1662.8MB downloaded\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"O1zhgV-uCcN2","executionInfo":{"status":"ok","timestamp":1614120608802,"user_tz":-330,"elapsed":925,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["words_ = model.index2word #word2vec orders words in decreasing order of frequency in the training corpus."],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNLgix_4DPlC","executionInfo":{"status":"ok","timestamp":1614120616939,"user_tz":-330,"elapsed":3567,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["word_rank = {}\r\n","\r\n","for i,word in enumerate(words_):\r\n","  word_rank[word] = i"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lUryiMBFjV4","executionInfo":{"status":"ok","timestamp":1614121224920,"user_tz":-330,"elapsed":1175,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["class Autocorrect:\r\n","\r\n","  def __init__(self, freq_rank_matrix):\r\n","    if freq_matrix is not None:\r\n","      self.word_freq_rank_matrix = freq_rank_matrix\r\n","    else:\r\n","      raise Exception(\"Empty freq matrix\")\r\n","    \r\n","  def __words(self,text): \r\n","    return re.findall(r'\\w+', text.lower())\r\n","\r\n","  def P(self, word): \r\n","    \"Probability of `word`.\"\r\n","    # use inverse of rank as proxy\r\n","    # returns 0 if the word isn't in the dictionary\r\n","    return - self.word_freq_rank_matrix.get(word, 0)\r\n","\r\n","  def correction(self,word): \r\n","    \"Most probable spelling correction for word.\"\r\n","    return max(candidates(word), key=P)\r\n","\r\n","  def candidates(self,word): \r\n","      \"Generate possible spelling corrections for word.\"\r\n","      return (self.__known([word]) or self.__known(EditDist1(word)) or self.__known(EditDist2(word)) or [word])\r\n","\r\n","  def __known(self,words): \r\n","      \"The subset of `words` that appear in the dictionary of word_freq_rank_matrix.\"\r\n","      return set(w for w in words if w in word_freq_rank_matrix)\r\n","\r\n","  def EditDist1(self,word):\r\n","      \"All edits that are one edit away from `word`.\"\r\n","      letters    = 'abcdefghijklmnopqrstuvwxyz'\r\n","      splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\r\n","      deletes    = [L + R[1:]               for L, R in splits if R]\r\n","      transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\r\n","      replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\r\n","      inserts    = [L + c + R               for L, R in splits for c in letters]\r\n","      return set(deletes + transposes + replaces + inserts)\r\n","\r\n","  def EditDist2(self,word): \r\n","      \"All edits that are two edits away from `word`.\"\r\n","      return (e2 for e1 in EditDist1(word) for e2 in EditDist1(e1))\r\n","    "],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4X5L_zkEV1E","executionInfo":{"status":"ok","timestamp":1614121244304,"user_tz":-330,"elapsed":1019,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["ac = Autocorrect(word_rank)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"H7v8WWMVEt_5","executionInfo":{"status":"ok","timestamp":1614121497893,"user_tz":-330,"elapsed":950,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}},"outputId":"d8d06277-a851-4e10-ad8e-66f6c6929ec6"},"source":["ac.correction('tippi')"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'tippy'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"cpsZ7zhYIB1L"},"source":["// Scribe"]},{"cell_type":"code","metadata":{"id":"XBixURvTIBPB","executionInfo":{"status":"ok","timestamp":1614121515704,"user_tz":-330,"elapsed":2850,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["import pandas as pd\r\n","word_freqrank_df =pd.DataFrame(word_rank.items(), columns=['word', 'freq'])\r\n","word_freqrank_df.head(10)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"ID55pqDzI9bW","executionInfo":{"status":"ok","timestamp":1614121579349,"user_tz":-330,"elapsed":5820,"user":{"displayName":"asuran r","photoUrl":"","userId":"13400439017930522440"}}},"source":["word_freqrank_df.to_csv(\"word2vec-google-news-300-index2word-wordfreqrank.csv\",index=False)\r\n","from google.colab import files\r\n","files.download(\"word2vec-google-news-300-index2word-wordfreqrank.csv\")"],"execution_count":49,"outputs":[]}]}